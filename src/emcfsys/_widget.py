"""
This module contains four napari widgets declared in
different ways:

- a pure Python function flagged with `autogenerate: true`
    in the plugin manifest. Type annotations are used by
    magicgui to generate widgets for each parameter. Best
    suited for simple processing tasks - usually taking
    in and/or returning a layer.
- a `magic_factory` decorated function. The `magic_factory`
    decorator allows us to customize aspects of the resulting
    GUI, including the widgets associated with each parameter.
    Best used when you have a very simple processing task,
    but want some control over the autogenerated widgets. If you
    find yourself needing to define lots of nested functions to achieve
    your functionality, maybe look at the `Container` widget!
- a `magicgui.widgets.Container` subclass. This provides lots
    of flexibility and customization options while still supporting
    `magicgui` widgets and convenience methods for creating widgets
    from type annotations. If you want to customize your widgets and
    connect callbacks, this is the best widget option for you.
- a `QWidget` subclass. This provides maximal flexibility but requires
    full specification of widget layouts, callbacks, events, etc.

References:
- Widget specification: https://napari.org/stable/plugins/building_a_plugin/guides.html#widgets
- magicgui docs: https://pyapp-kit.github.io/magicgui/

Replace code below according to your needs.
"""

from typing import TYPE_CHECKING

import numpy as np
from magicgui import magic_factory
from magicgui.widgets import CheckBox, ComboBox, Container, create_widget, PushButton
from qtpy.QtWidgets import QHBoxLayout, QPushButton, QWidget, QVBoxLayout


from scipy import ndimage
from skimage.transform import resize
from skimage.util import img_as_float
import os
if TYPE_CHECKING:
    import napari



# the magic_factory decorator lets us customize aspects of our widget
# we specify a widget type for the threshold parameter
# and use auto_call=True so the function is called whenever
# the value of a parameter changes
backbone_zoom = [   "emcellfound_vit_base",
                 
                    "resnet34", "resnet50", "resnet101", 
                
                    "convnext_tiny", "convnext_small", "convnext_base", "convnext_large",
                    
                    "efficientnet_b0", "efficientnet_b2", 
                    "efficientnet_b4" , "efficientnet_b6", 
                    "efficientnet_b7",
                    
                    "efficientnetv2_s", "efficientnetv2_m", "efficientnetv2_l",
                    
                    "rexnetr_200.sw_in12k", "rexnetr_300.sw_in12k", 
                    
                    "vit_base_patch32_clip_448.laion2b_ft_in12k_in1k", 
                    "vit_so400m_patch14_siglip_gap_448.pali_refcoco_seg",
                    
                    "vit_small_patch16_dinov3.lvd1689m", "vit_base_patch16_dinov3.lvd1689m",
                    "vit_large_patch16_dinov3.lvd1689m", "vit_huge_patch16_dinov3.lvd1689m"]


model_zoom = ["deeplabv3plus", "unet", "pspnet", "upernet"]

class ImageResize(Container):
    """Container widget for resizing images with different interpolation algorithms."""

    def __init__(self, viewer: "napari.viewer.Viewer"):
        super().__init__()
        self._viewer = viewer

        # Image selection
        self._image_layer_combo = create_widget(
            label="Image", annotation="napari.layers.Image"
        )

        # Output size widgets
        self._width_spinbox = create_widget(
            label="Width", annotation=int, widget_type="SpinBox"
        )
        self._width_spinbox.min = 1
        self._width_spinbox.max = 10000
        self._width_spinbox.value = 512

        self._height_spinbox = create_widget(
            label="Height", annotation=int, widget_type="SpinBox"
        )
        self._height_spinbox.min = 1
        self._height_spinbox.max = 10000
        self._height_spinbox.value = 512

        # Scale factor widgets
        self._scale_x_spinbox = create_widget(
            label="Scale X", annotation=float, widget_type="FloatSpinBox"
        )
        self._scale_x_spinbox.min = 0.01
        self._scale_x_spinbox.max = 100.0
        self._scale_x_spinbox.value = 1.0
        self._scale_x_spinbox.step = 0.1

        self._scale_y_spinbox = create_widget(
            label="Scale Y", annotation=float, widget_type="FloatSpinBox"
        )
        self._scale_y_spinbox.min = 0.01
        self._scale_y_spinbox.max = 100.0
        self._scale_y_spinbox.value = 1.0
        self._scale_y_spinbox.step = 0.1

        # Resize mode selection
        self._mode_combo = ComboBox(
            label="Resize Mode",
            choices=["Absolute Size", "Scale Factor"],
            value="Absolute Size",
        )

        # Interpolation algorithm selection
        self._algorithm_combo = ComboBox(
            label="Algorithm",
            choices=[
                "Nearest Neighbor",
                "Bilinear",
                "Bicubic",
                "Lanczos",
            ],
            value="Bilinear",
        )

        # Maintain aspect ratio checkbox
        self._maintain_aspect_checkbox = CheckBox(text="Maintain Aspect Ratio")

        # Apply button
        self._apply_button = PushButton(text="Apply Resize!")
        self._apply_button.clicked.connect(self._resize_image)

        # Add all widgets to container
        self.extend(
            [
                self._image_layer_combo,
                self._mode_combo,
                self._width_spinbox,
                self._height_spinbox,
                self._scale_x_spinbox,
                self._scale_y_spinbox,
                self._maintain_aspect_checkbox,
                self._algorithm_combo,
                self._apply_button,
            ]
        )

        # Connect callbacks
        self._image_layer_combo.changed.connect(self._on_image_changed)
        self._mode_combo.changed.connect(self._on_mode_changed)
        self._width_spinbox.changed.connect(self._on_size_changed)
        self._height_spinbox.changed.connect(self._on_size_changed)

        # Initialize visibility
        self._on_mode_changed()

    # -------------------
    # Callback methods
    # -------------------
    def _on_image_changed(self):
        """Update size spinboxes when image is selected."""
        image_layer = self._image_layer_combo.value
        if image_layer is not None and hasattr(image_layer, "data"):
            shape = image_layer.data.shape
            if len(shape) >= 2:
                self._height_spinbox.value = shape[-2]
                self._width_spinbox.value = shape[-1]

    def _on_mode_changed(self):
        """Toggle visibility of size/scale widgets based on mode."""
        mode = self._mode_combo.value
        if mode == "Absolute Size":
            self._width_spinbox.show()
            self._height_spinbox.show()
            self._scale_x_spinbox.hide()
            self._scale_y_spinbox.hide()
        else:  # Scale Factor
            self._width_spinbox.hide()
            self._height_spinbox.hide()
            self._scale_x_spinbox.show()
            self._scale_y_spinbox.show()

    def _on_size_changed(self):
        """Maintain aspect ratio in absolute size mode."""
        if not self._maintain_aspect_checkbox.value:
            return

        image_layer = self._image_layer_combo.value
        if image_layer is None or not hasattr(image_layer, "data"):
            return

        shape = image_layer.data.shape
        if len(shape) < 2:
            return

        original_height, original_width = shape[-2], shape[-1]
        aspect_ratio = original_width / original_height

        sender = self.sender()
        if sender == self._width_spinbox:
            new_width = self._width_spinbox.value
            new_height = int(new_width / aspect_ratio)
            self._height_spinbox.value = new_height
        elif sender == self._height_spinbox:
            new_height = self._height_spinbox.value
            new_width = int(new_height * aspect_ratio)
            self._width_spinbox.value = new_width

    # -------------------
    # Resize operation
    # -------------------
    def _resize_image(self):
        image_layer = self._image_layer_combo.value
        if image_layer is None:
            return

        image = image_layer.data
        mode = self._mode_combo.value
        algorithm = self._algorithm_combo.value

        # Determine output shape
        if mode == "Absolute Size":
            output_height = self._height_spinbox.value
            output_width = self._width_spinbox.value
        else:  # Scale Factor
            scale_y = self._scale_y_spinbox.value
            scale_x = self._scale_x_spinbox.value
            original_shape = image.shape
            output_height = int(original_shape[-2] * scale_y)
            output_width = int(original_shape[-1] * scale_x)

        # Map algorithm names
        algorithm_map = {"Nearest Neighbor": 0, "Bilinear": 1, "Bicubic": 3, "Lanczos": None}

        try:
            # Determine output shape for different dimensions
            if len(image.shape) == 2:
                output_shape = (output_height, output_width)
            elif len(image.shape) == 3:
                if image.shape[-1] in [3, 4]:  # RGB / RGBA
                    output_shape = (output_height, output_width, image.shape[-1])
                else:  # 3D grayscale
                    output_shape = (
                        int(image.shape[0] * (output_height / image.shape[-2])),
                        output_height,
                        output_width,
                    )
            else:
                scale_factors = [1.0] * len(image.shape)
                scale_factors[-2] = output_height / image.shape[-2]
                scale_factors[-1] = output_width / image.shape[-1]
                output_shape = tuple(
                    int(s * f) for s, f in zip(image.shape, scale_factors)
                )

            # Perform resize
            if algorithm == "Lanczos":
                resized = resize(
                    image, output_shape, order=3, mode="reflect", anti_aliasing=True
                )
            else:
                order = algorithm_map[algorithm]
                if len(image.shape) == 2:
                    resized = ndimage.zoom(
                        image,
                        (output_height / image.shape[0], output_width / image.shape[1]),
                        order=order,
                    )
                elif len(image.shape) == 3 and image.shape[-1] in [3, 4]:
                    resized = np.zeros(output_shape, dtype=image.dtype)
                    for i in range(image.shape[-1]):
                        resized[..., i] = ndimage.zoom(
                            image[..., i],
                            (
                                output_height / image.shape[0],
                                output_width / image.shape[1],
                            ),
                            order=order,
                        )
                else:
                    zoom_factors = [
                        out_s / in_s for out_s, in_s in zip(output_shape, image.shape)
                    ]
                    resized = ndimage.zoom(image, zoom_factors, order=order)

            # Add resized image as new layer
            name = image_layer.name + "_resized"
            if name in self._viewer.layers:
                self._viewer.layers[name].data = resized
            else:
                self._viewer.add_image(resized, name=name)

        except Exception as e:
            print(f"Error resizing image: {e}")



#-----------model test
from magicgui.widgets import Container, FileEdit, FloatSpinBox, SpinBox, ComboBox, PushButton, Label, TextEdit, SpinBox
# from qtpy.QtWidgets import QTextEdit
from napari.qt.threading import thread_worker
import torch
import numpy as np
from .EMCellFound.inference import load_model
# -----------------------------
# DL Inference Container
# -----------------------------
class DLInferenceContainer(Container):
    def __init__(self, viewer: "napari.viewer.Viewer"):
        super().__init__()
        self._viewer = viewer
        # widgets
        self.model_path = FileEdit(label="Model (.pt/.pth/.ptscript)")
        
        # 使用 create_widget 支持直接选择 napari Image layer
        self._image_layer_combo = create_widget(
            label="Image", annotation="napari.layers.Image"
        )
        
        self.num_classes = SpinBox(label="num classes", min=2, max=1000, step=1, value=2)
        
        self.device = ComboBox(label="Device", choices=["auto", "cpu", "cuda"], value="auto")
        self.backbone_name = ComboBox(label="Backbone", choices=backbone_zoom, value="emcellfound_vit_base")
        self.model_name = ComboBox(label="Model", choices=model_zoom, value="deeplabv3plus")
        self.img_size = SpinBox(label="Image size to model", min=1, max=4096, step=1, value=512)
        self.slide_window_size = SpinBox(label="Slide window size", min=1, max=4096, step=1, value=512)
        
        self._run_button_full = PushButton(text="Run Full Inference")
        self._run_button_slide = PushButton(text="Run Slide Inference")

        # add widgets
        self.extend([self.model_path, 
                     self._image_layer_combo, 
                     self.backbone_name, self.model_name,
                     self.num_classes, self.device, 
                     self.img_size,
                     self.slide_window_size,
                     self._run_button_full, self._run_button_slide])

        # connect
        self._run_button_full.clicked.connect(self._run_inference_full)
        self._run_button_slide.clicked.connect(self._run_inference_slide)

    def _run_inference_full(self):
        img_layer = self._image_layer_combo.value
        if img_layer is None:
            return

        img = img_layer.data
        device = self.device.value
        dev = torch.device(device) if device != "auto" else None
        model_path = self.model_path.value

        print("image_layer:", img.shape)

        @thread_worker
        def _worker():
            from .EMCellFound.inference import infer_full_image
            model = load_model(
                    model_name=self.model_name.value, 
                    backbone_name=self.backbone_name.value, 
                    num_classes=self.num_classes.value, 
                    model_path=model_path, 
                    aux_on=False, 
                    device=dev)
            
            return infer_full_image(model, img, input_size=(self.img_size.value, self.img_size.value), device=dev)

        worker = _worker()

        def on_result(mask: np.ndarray):
            name = img_layer.name + "_dl_mask"
            if name in self._viewer.layers:
                self._viewer.layers[name].data = mask
            else:
                self._viewer.add_labels(mask, name=name)

        worker.returned.connect(on_result)
        worker.start()

    def _run_inference_slide(self):
        img_layer = self._image_layer_combo.value
        if img_layer is None:
            return

        img = img_layer.data
        device = self.device.value
        dev = torch.device(device) if device != "auto" else None
        model_path = self.model_path.value


        @thread_worker
        def _worker():
            from .EMCellFound.inference import infer_sliding_window
            model = load_model(
                    model_name=self.model_name.value, 
                    backbone_name=self.backbone_name.value, 
                    num_classes=self.num_classes.value, 
                    model_path=model_path, 
                    aux_on=False, 
                    device=dev)
            
            return infer_sliding_window(model, 
                                        img, 
                                        window_size=self.slide_window_size.value,
                                        img_size=(self.img_size.value, self.img_size.value), 
                                        out_channels = self.num_classes.value,
                                        device=dev)

        worker = _worker()

        def on_result(mask: np.ndarray):
            name = img_layer.name + "_slide_mask"
            if name in self._viewer.layers:
                self._viewer.layers[name].data = mask
            else:
                self._viewer.add_labels(mask, name=name)

        worker.returned.connect(on_result)
        worker.start()

from magicgui.widgets import FileEdit, FloatSpinBox, SpinBox, ComboBox, PushButton, Label, TextEdit, Widget
# from magicgui import Container
from pathlib import Path
import torch
from napari.qt.threading import thread_worker
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from qtpy.QtWidgets import QWidget, QVBoxLayout


class DLTrainingContainer(Container):

    def __init__(self, viewer: "napari.viewer.Viewer"):
        super().__init__()
        self._viewer = viewer
        self._stop_flag = False
        
        # widgets
        self.images_dir = FileEdit(label="Images folder", mode="d")
        self.masks_dir = FileEdit(label="Masks folder", mode="d")
        self.save_path = FileEdit(label="Save model as (.pth)", mode="d")
        self.pretrained_model = FileEdit(label="Pretrained model (.pth)", nullable=True, mode="r")

        self.backbone_name = ComboBox(label="Backbone", choices=backbone_zoom, value="resnet34")
        self.model_name = ComboBox(label="Model", choices=model_zoom, value="deeplabv3plus")

        self.lr = FloatSpinBox(label="Learning rate", min=1e-8, max=1.0, step=1e-4, value=1e-4)
        self.batch_size = SpinBox(label="Batch size", min=1, max=512, step=1, value=8)
        self.epochs = SpinBox(label="Epochs", min=1, max=1000, step=10, value=100)
        self.device = ComboBox(label="Device", choices=["auto", "cpu", "cuda"], value="auto")

        self.classes_num = SpinBox(label="Classes num", min=2, max=1000, step=1, value=2)
        # self.in_channels = SpinBox(label="Image channels", min=1, max=3, step=1, value=3)
        self.target_size = SpinBox(label="Target size", min=1, max=10**8, value=512)
        self.ignore_index = SpinBox(label="Ignore the index in mask", min=-1, max=10**8, value=-1)

        self._train_button = PushButton(text="Start Training")
        self._stop_button = PushButton(text="Stop Training")
        self._log_label = Label(value="Training log:")
        
        self._log_widget = TextEdit()
        self._log_widget.read_only = True
        self._log_widget.native.setMinimumHeight(180)

        # add widgets
        self.extend([
            self.images_dir, self.masks_dir, self.save_path, self.pretrained_model,
            self.backbone_name, self.model_name,
            self.lr, self.batch_size, self.epochs, self.device,
            self.classes_num,  self.target_size,
            self.ignore_index,
            self._train_button, self._stop_button, self._log_label, 
            self._log_widget
        ])

        # connect signals
        self._train_button.clicked.connect(self._start_training)
        self._stop_button.clicked.connect(self._stop_training)


        # ---------------- Loss Curve ----------------
        # ---------------- Loss Curve ----------------
        self._fig, self._ax = plt.subplots()
        self._ax.set_xlabel("Epoch")
        self._ax.set_ylabel("Loss")
        self._ax.set_title("Training Loss Curve")
        self._canvas = FigureCanvas(self._fig)

        # 用 QWidget 包装 FigureCanvas
        self._canvas_widget = QWidget()
        v_layout = QVBoxLayout()
        v_layout.addWidget(self._canvas)
        self._canvas_widget.setLayout(v_layout)
        # 添加到 Napari dock
        if self._viewer is not None:
            self._viewer.window.add_dock_widget(self._canvas_widget, name="Loss Curve", area="right")

        # 用于绘制曲线
        self._x_values = []
        self._y_values = []


    def _log(self, s):
        try:
            self._log_widget.append(s)
        except Exception:
            print(s)
            
            
    # --------------------------- LOSS CURVE ---------------------------
    def _update_loss_curve(self, loss, epoch=None):
        # 支持 batch 或 epoch 级别绘制
        if epoch is not None:
            self._x_values.append(epoch)
            self._y_values.append(loss)
        # else:
        #     # batch 级别直接追加
        #     self._x_values.append(len(self._x_values)+1)
        #     self._y_values.append(loss)
        self._ax.clear()
        self._ax.set_xlabel("Epoch")
        self._ax.set_ylabel("Loss")
        self._ax.set_title("Training Loss Curve")
        self._ax.plot(self._x_values, self._y_values, color='blue')
        self._fig.tight_layout()
        self._canvas.draw_idle()
    # ------------------------ TRAINING LOGIC --------------------------
    
    
    def _start_training(self):
        if self._viewer is None:
            return

        self._stop_flag = False  # 重置停止标志
        self._ax.cla()
        self._canvas.draw()
        
        # -------✔ 完整重置 loss 曲线 -------
        self._x_values = []
        self._y_values = []

        self._ax.clear()
        self._ax.set_xlabel("Epoch")
        self._ax.set_ylabel("Loss")
        self._ax.set_title("Training Loss Curve")
        self._fig.tight_layout()
        self._canvas.draw()
        
        images_dir = self.images_dir.value
        masks_dir = self.masks_dir.value
        save_path = self.save_path.value
        pretrained_model = self.pretrained_model.value
        backbone_name = self.backbone_name.value
        model_name = self.model_name.value
        lr = self.lr.value
        batch_size = self.batch_size.value
        epochs = self.epochs.value
        device = self.device.value
        # in_channels = self.in_channels.value
        classes_num = self.classes_num.value
        target_size = self.target_size.value
        ignore_index = self.ignore_index.value
        dev = torch.device(device) if device != "auto" else torch.device("cuda" if torch.cuda.is_available() else "cpu")

        from .EMCellFound.train import train_loop  # 自己的训练函数
        
        
        @thread_worker
        def _worker():
            logs = []
            epoch_times = []
            metrics_all = []
            def cb(epoch, batch, n_batches, loss, finished_epoch=False, epoch_time=None, model_dict=None, metrics=None):
                # 更新 loss 曲线
                if finished_epoch:
                    self._update_loss_curve(loss, epoch=epoch)
                # else:
                #     self._update_loss_curve(loss, epoch=epoch)

                # 保存 epoch 时间
                if finished_epoch and epoch_time is not None:
                    epoch_times.append(epoch_time)
                    if len(epoch_times) == 1:
                        estimated_total = epoch_times[0] * epochs
                        self._log(f"Estimated total training time: {estimated_total:.2f}s (~{estimated_total/60:.1f} min)")

                if metrics is not None:
                    metrics_all.append(metrics)
                    
                # 保存 batch/epoch 日志
                logs.append((epoch, batch, n_batches, loss, finished_epoch, epoch_time, metrics))

                # 输出日志
                if batch == 0 and finished_epoch:
                    if epoch_time is not None:
                        self._log(f"Epoch {epoch} finished, avg loss {loss:.4f}, time {epoch_time:.2f}s, metric {metrics}" )
                #     else:
                #         self._log(f"Epoch {epoch} finished, avg loss {loss:.4f}")
                # else:
                #     self._log(f"Epoch {epoch} batch {batch}/{n_batches} loss {loss:.4f}")

                # 停止训练
                if self._stop_flag and model_dict is not None:
                    interrupted_path = os.path.join(save_path, "interrupted_model.pth")
                    torch.save(model_dict, interrupted_path)
                    self._log(f"Training stopped. Model saved to {interrupted_path}")
                    raise StopIteration()

            try:
                train_loop(images_dir, masks_dir, save_path,
                        model_name=model_name,
                        backbone_name=backbone_name,
                        pretrained = True,
                        pretrained_model=pretrained_model,
                        lr=lr, batch_size=batch_size, epochs=epochs,
                        device=dev, callback=cb,
                        target_size=(target_size, target_size),
                        classes_num=classes_num,
                        ignore_index = ignore_index,
                        stop_flag_fn=lambda: self._stop_flag
                    )
            except StopIteration:
                self._log("Training stopped by user.")

            return logs

        worker = _worker()

        def on_returned(logs):
            for t in logs:
                epoch, batch, n_batches, loss, finished, epoch_time, metrics_info = t
                if batch == 0:
                    if epoch_time is not None:
                        self._log(f"Epoch {epoch} finished, avg loss {loss:.4f}, time {epoch_time:.2f}s, metric {metrics_info}")
                    else:
                        self._log(f"Epoch {epoch} finished, avg loss {loss:.4f}")
                else:
                    self._log(f"Epoch {epoch} batch {batch}/{n_batches} loss {loss:.4f}")
            if not self._stop_flag:
                self._log(f"Training finished. Model saved to: {save_path}")

        worker.returned.connect(on_returned)
        worker.start()

    def _stop_training(self):
        self._stop_flag = True
        self._log("Stop button clicked. Stopping training...")

    def _cleanup_gpu(self):
        import gc
        torch.cuda.empty_cache()
        gc.collect()
        self._log("GPU memory released.")





#------------EMCellFiner=------
#------------EMCellFiner=------

from qtpy.QtWidgets import QWidget, QVBoxLayout, QGroupBox
from magicgui import magicgui
from .EMCellFiner.hat.models.hat_model import HATModel
from .EMCellFiner.hat.models.img_utils import tensor2img
from .EMCellFiner.hat.models.inference_hat import hat_infer_numpy
from PIL import Image
import numpy as np
import torch
import numpy as np
from magicgui.widgets import create_widget, ComboBox, Container, FileEdit, PushButton
from napari.qt.threading import thread_worker
from napari.layers import Image as ImageLayer
import napari

class EMCellFinerSingleInferWidget(Container):
    def __init__(self, viewer: "napari.viewer.Viewer"):
        super().__init__()
        self.viewer = viewer

        MODEL_ZOO = ["EMCellFiner"]
        
        self.model_path = FileEdit(label="Model (.pth)", nullable=True, mode="r")
        
        # 修复：annotation 必须是类型，不是字符串
        self._image_layer_combo = create_widget(
            label="Image",
            annotation=ImageLayer
        )
        
        self.device = ComboBox(label="Device", choices=["auto", "cpu", "cuda"], value="auto")
        self.scale = ComboBox(label="Scale", choices=[1, 2, 4], value=4)
        self.tile_size = ComboBox(label="Tile Size", choices=[256, 384, 512, 640], value=512)
        self.model_choice = ComboBox(label="Model", choices=MODEL_ZOO, value="EMCellFiner")
        
        self._run_button = PushButton(text="Run Inference")
        
        self.extend([
            self.model_choice, self.model_path, 
            self._image_layer_combo, self.scale, 
            self.tile_size, self.device, self._run_button
        ])

        # 修复：不加括号，绑定函数本体
        self._run_button.clicked.connect(self._run_inference)
            

    # ==================================================
    #                 深度学习推理（多线程）
    # ==================================================
    def _run_inference(self):
        img_layer = self._image_layer_combo.value
        if img_layer is None:
            print("No layer selected")
            return
        


        # 读取 UI 参数
        model_path = self.model_path.value
        scale = self.scale.value
        tile_size = self.tile_size.value
        device = self.device.value
        if device == "auto":
            device = "cuda" if torch.cuda.is_available() else "cpu"
        
        if model_path in ["None", "", None]:
            model_path = None

        img_np = img_layer.data
        
        # 单通道 -> 3通道
        if img_np.ndim == 2:
            img_np = np.stack([img_np] * 3, axis=-1)
        elif img_np.shape[-1] == 1:
            img_np = np.repeat(img_np, 3, axis=-1)


        # ---- 在执行推理前启动进度条 ----
        progress = napari.utils.progress(total=100, desc="EMCellFiner Inference...")


        # ---- 启动线程 ----
        @thread_worker
        def _worker():
            # 模型加载
            model = HATModel(
                local_path=model_path,
                scale=scale,
                tile_size=tile_size,
            )

            # 推理（你自己的函数）
            # 在推理中调用 progress.update(x) 也可以
            output_np = hat_infer_numpy(model, img_np, device)

            return output_np

        worker = _worker()

        # ---- 推理完成后回到主线程处理结果 ----
        @worker.returned.connect
        def _on_result(output_np):
            progress.close()
            self.viewer.add_image(
                output_np,
                name=f"{img_layer.name}_EMCFiner_SR",
            )
            print("✔ Inference Finished")

        # ---- 推理出错处理 ----
        @worker.errored.connect
        def _on_error(err):
            progress.close()
            print("❌ Inference Error:", err)

        worker.start()


from qtpy.QtWidgets import QWidget, QVBoxLayout, QGroupBox
from magicgui import magicgui
import os
import numpy as np
from PIL import Image


from qtpy.QtWidgets import QWidget, QVBoxLayout, QGroupBox
from magicgui import magicgui
import os
import numpy as np
from glob import glob
from PIL import Image
from magicgui.widgets import create_widget, ComboBox, Container, FileEdit, PushButton, LineEdit
from napari.qt.threading import thread_worker
import napari


class EMCellFinerBatchInferWidget(Container):
    def __init__(self, viewer: "napari.viewer.Viewer"):
        super().__init__()
        self.viewer = viewer

        MODEL_ZOO = ["EMCellFiner"]

        self.model_path = FileEdit(label="Model (.pth)", mode="r", nullable=True)

        self.input_dir = FileEdit(label="Input Folder", mode="d")
        self.output_dir = FileEdit(label="Save Folder", mode="d")

        self.scale = ComboBox(label="Scale", choices=[1, 2, 4], value=4)
        self.tile_size = ComboBox(label="Tile Size", choices=[256, 384, 512, 640], value=512)
        self.device = ComboBox(label="Device", choices=["auto", "cpu", "cuda"], value="auto")
        self.model_choice = ComboBox(label="Model", choices=MODEL_ZOO, value="EMCellFiner")

        self._run_button = PushButton(text="Run Batch Inference")
        self._stop_button = PushButton(text="Stop Inference")
        
        self.extend([
            self.model_choice, self.model_path,
            self.input_dir, self.output_dir,
            self.scale, self.tile_size, self.device,
            self._run_button, self._stop_button
        ])

        # 按钮绑定
        self._run_button.clicked.connect(self._run_batch_inference)
        self._stop_button.clicked.connect(self._stop_worker)
        

        # 保存 worker 对象和 stop flag
        self._worker = None
        self._stop_flag = False

        
    def _stop_worker(self):
        self._stop_flag = True
        if self._worker is not None:
            self._worker.quit()
            print("⚠ Batch inference stopped by user.")
            
    # ==================================================
    #               多张图推理的多线程函数
    # ==================================================
    def _run_batch_inference(self):
        input_dir = self.input_dir.value
        output_dir = self.output_dir.value
        model_path = self.model_path.value
        
        if model_path in ["None", "", ".", None]:
            model_path = None
            
            
        if not (input_dir and os.path.isdir(input_dir)):
            print("❌ Invalid Input Folder")
            return

        if not (output_dir and os.path.isdir(output_dir)):
            print("❌ Invalid Output Folder")
            return

        # 搜索所有图像
        img_files = []
        for ext in ["*.png", "*.jpg", "*.jpeg", "*.tif", "*.tiff", "*.bmp"]:
            img_files.extend(glob(os.path.join(input_dir, ext)))

        if len(img_files) == 0:
            print("❌ No images found in folder")
            return

        scale = self.scale.value
        tile_size = self.tile_size.value
        device = self.device.value
        device = "cuda" if torch.cuda.is_available() else "cpu" if device == "auto" else device
        
        # 重置 stop flag
        self._stop_flag = False

        # napari 进度条
        progress = napari.utils.progress(range(len(img_files)), desc="Batch Inference...")

        @thread_worker
        def _worker():
            # 加载模型一次
            model = HATModel(
                local_path=model_path,
                scale=scale,
                tile_size=tile_size,
            )

            for idx, path in enumerate(img_files):
                if self._stop_flag:
                    print("⚠ Worker stopped by user")
                    break

                # 打开图片并转换成 RGB
                img = np.array(Image.open(path).convert("RGB"))
                # 保证img是unit8
                
                
                out_np = hat_infer_numpy(model, img, device)

                # 每张图推理完成就返回主线程处理
                yield path, out_np, idx

        self._worker = _worker()
        worker = self._worker

        # ----------------------------
        # 每张图推理完成回调
        # ----------------------------
        @worker.yielded.connect
        def _on_each(args):
            path, out_np, idx = args
            save_path = os.path.join(output_dir, os.path.basename(path))
            Image.fromarray(out_np).save(save_path)
            print(f"idx: {idx} : {os.path.basename(path)} Saved to: ", save_path)
            progress.update(idx + 1)

        @worker.errored.connect
        def _on_err(err):
            progress.close()
            print("❌ Error:", err)

        @worker.finished.connect
        def _on_finished():
            progress.close()
            print("✔ Batch Inference Finished")
            self._worker = None  # 清理 worker 对象
            self._stop_flag = False
        worker.start()
        